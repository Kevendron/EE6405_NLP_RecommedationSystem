# -*- coding: utf-8 -*-
"""Final_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TEcR8oSHCGAsgHWvPrfbB6dcF5tTfPco

[link text](https://) This is the main code for applying the single tower model Architecture for personlised recomnedation system :
"""

import json
from pathlib import Path
from typing import List, Dict, Optional

import numpy as np
import pandas as pd
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

DATA_DIR   = Path("/content/drive/MyDrive/Data/preprocessed_data/Electronics")
ARTIFACTS  = DATA_DIR / "optionB_nlp_model"
ARTIFACTS.mkdir(parents=True, exist_ok=True)

TEXT_EMB_DIM = 384   # MiniLM output size
EMB_D        = 128   # projected embedding size

MAX_HIST   = 10
TEMP       = 0.07

EPOCHS       = 5
BATCH_SIZE   = 256
EVAL_BS      = 512
LR           = 3e-4
WEIGHT_DECAY = 1e-4
SEED         = 42

MAX_TRAIN_ROWS = 200_000
MAX_VALID_ROWS = 30_000
MAX_TEST_ROWS  = 30_000

VAL_MAX_BATCHES  = 5
TEST_MAX_BATCHES = 5


def set_seed(seed: int = SEED):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def pad_sequences(seqs: List[List[int]], max_len: int, pad_val: int = -1):
    """
    Right-pad sequences to max_len with pad_val.
    Returns:
      x: (B, L) indices (may contain pad_val)
      mask: (B, L) bool, True for real token, False for pad
    """
    B = len(seqs)
    x = torch.full((B, max_len), pad_val, dtype=torch.long)
    m = torch.zeros((B, max_len), dtype=torch.bool)
    for i, s in enumerate(seqs):
        s = s[-max_len:]              # keep most recent K
        L = len(s)
        if L > 0:
            x[i, :L] = torch.tensor(s, dtype=torch.long)
            m[i, :L] = True
    return x, m


class TriplesDS(Dataset):
    """
    Reads train/valid/test jsonl with:
      {"user_id": "...", "user_idx": int,
       "history": [item_idx, ...], "target": int, "ts": int}
    We only use (history, target_idx).
    """
    def __init__(self, path: Path, max_rows: Optional[int] = None, name: str = ""):
        self.rows = []
        print(f"Loading {name or path.name} from {path} ...")

        with open(path, "r", encoding="utf-8") as f:
            for i, line in enumerate(f, start=1):
                line = line.strip()
                if not line:
                    continue
                r = json.loads(line)
                hist = r.get("history", [])
                if len(hist) == 0:
                    continue
                self.rows.append({
                    "history":  hist,
                    "target":   r["target"],
                })

                if i % 1_000_000 == 0:
                    print(f"  read {i:,} lines, kept {len(self.rows):,} rows so far...")

                if max_rows is not None and i >= max_rows:
                    print(f"  reached max_rows={max_rows:,}, stopping read.")
                    break

        print(f"  -> finished {name or path.name}: {len(self.rows):,} rows kept.")
        if len(self.rows) == 0:
            print("  [WARN] zero rows loaded â€“ check file & 'history' field.")

    def __len__(self):
        return len(self.rows)

    def __getitem__(self, idx):
        r = self.rows[idx]
        return {
            "history":  r["history"],
            "target":   r["target"],
        }

def collate_fn(batch):
    histories = [b["history"] for b in batch]
    targets   = torch.tensor([b["target"] for b in batch], dtype=torch.long)
    hist_idx, hist_mask = pad_sequences(histories, MAX_HIST, pad_val=-1)
    return {
        "hist_idx":  hist_idx,
        "hist_mask": hist_mask,
        "target_idx": targets,
    }


class ItemProjector(nn.Module):
    """
    Small MLP on top of frozen MiniLM embeddings:
      384 -> 256 -> 128 -> L2-normalized
    """
    def __init__(self, in_dim: int = TEXT_EMB_DIM, out_dim: int = EMB_D, hidden_dim: int = 256):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, out_dim),
        )

    def forward(self, x: torch.Tensor):
        # x: (..., in_dim)
        z = self.mlp(x)
        z = F.normalize(z, dim=-1)
        return z


def info_nce_logits(user: torch.Tensor, pos_item: torch.Tensor, temp: float = 0.07):
    # user: (B,D), pos_item: (B,D)
    return (user @ pos_item.t()) / temp        # (B,B), in-batch negatives

def recall_at_k(scores_row: np.ndarray, target_idx: int, k: int) -> float:
    topk = np.argpartition(-scores_row, k)[:k]
    return 1.0 if target_idx in topk else 0.0

def eval_full_knn(
    model: ItemProjector,
    dataloader: DataLoader,
    device: torch.device,
    base_text_emb_t: torch.Tensor,    # (N, TEXT_EMB_DIM) on device
    Ks=(10, 20, 50),
    max_batches: Optional[int] = None,
):
    """
    Evaluate Recall@K / NDCG@K by:
      - projecting ALL item embeddings once
      - for each batch, computing user embedding = mean(projected history)
      - scoring vs all items
    Only uses subset of batches if max_batches is set.
    """
    model.eval()
    with torch.no_grad():
        # Precompute projected item embeddings (N, EMB_D)
        E_item = model(base_text_emb_t)            # (N, D)
        E_item_np = E_item.cpu().numpy()

        metrics: Dict[str, List[float]] = {f"recall@{k}": [] for k in Ks}
        metrics.update({f"ndcg@{k}": [] for k in Ks})
        total_users = 0

        for b_idx, batch in enumerate(tqdm(dataloader, desc="Eval", leave=True)):
            if max_batches is not None and b_idx >= max_batches:
                break

            hist_idx  = batch["hist_idx"].to(device)   # (B,L)
            hist_mask = batch["hist_mask"].to(device)  # (B,L)
            target_idx = batch["target_idx"].to(device)# (B,)

            # user embedding: mean over projected item embeddings from E_item
            B, L = hist_idx.shape
            # safe indices: replace -1 with 0
            safe_idx = hist_idx.clone()
            safe_idx[~hist_mask] = 0

            # (B,L,D)
            hist_emb = E_item[safe_idx]        # gather projected emb
            m = hist_mask.float().unsqueeze(-1)
            summed = (hist_emb * m).sum(dim=1)     # (B,D)
            count  = m.sum(dim=1).clamp(min=1.0)   # (B,1)
            user = summed / count
            user = F.normalize(user, dim=-1)       # (B,D)

            scores = user @ E_item.t()             # (B,N)
            scores_np = scores.cpu().numpy()
            tgt_np    = target_idx.cpu().numpy()

            B_now = scores_np.shape[0]
            total_users += B_now

            for i in range(B_now):
                row = scores_np[i]
                t   = int(tgt_np[i])
                for k in Ks:
                    # Recall@K
                    metrics[f"recall@{k}"].append(recall_at_k(row, t, k))
                    # NDCG@K (binary relevance)
                    topk = np.argsort(row)[::-1][:k]
                    rel = np.zeros(k, dtype=float)
                    if t in topk:
                        rel[np.where(topk == t)[0][0]] = 1.0
                    dcg = (rel / np.log2(np.arange(2, k+2))).sum()
                    metrics[f"ndcg@{k}"].append(dcg)

        print(f"  [eval] computed metrics on {total_users:,} users.")
        return {k: float(np.mean(v)) for k, v in metrics.items()}, E_item_np


def main():
    from sentence_transformers import SentenceTransformer

    set_seed()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Device:", device)

    items_df = pd.read_parquet(DATA_DIR / "items.parquet")
    with open(DATA_DIR / "mappings.json", "r", encoding="utf-8") as f:
        maps = json.load(f)
    item2idx = maps["item2idx"]
    num_items = len(item2idx)
    print(f"Num items: {num_items:,}")

    assert len(items_df) == num_items, "items.parquet rows must match num_items"

    base_path = DATA_DIR / "item_text_emb_384.npy"
    if base_path.exists():
        base_text_emb = np.load(base_path)
        print("Loaded base_text_emb:", base_text_emb.shape)
    else:
        print("Computing MiniLM embeddings for all item_texts...")
        model_st = SentenceTransformer("all-MiniLM-L6-v2")
        texts = items_df["item_text"].tolist()
        base_text_emb = model_st.encode(
            texts,
            batch_size=128,
            show_progress_bar=True,
        )
        base_text_emb = np.asarray(base_text_emb, dtype=np.float32)
        np.save(base_path, base_text_emb)
        print("Saved base_text_emb:", base_text_emb.shape)

    assert base_text_emb.shape == (num_items, TEXT_EMB_DIM)

    base_text_emb_t = torch.from_numpy(base_text_emb).to(device=device, dtype=torch.float32)

    train_ds = TriplesDS(DATA_DIR / "train.jsonl", max_rows=MAX_TRAIN_ROWS, name="train.jsonl")
    valid_ds = TriplesDS(DATA_DIR / "valid.jsonl", max_rows=MAX_VALID_ROWS, name="valid.jsonl")
    test_ds  = TriplesDS(DATA_DIR / "test.jsonl",  max_rows=MAX_TEST_ROWS,  name="test.jsonl")

    print(f"Train triples: {len(train_ds):,} | Valid: {len(valid_ds):,} | Test: {len(test_ds):,}")

    train_dl = DataLoader(
        train_ds,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        collate_fn=collate_fn,
    )
    valid_dl = DataLoader(
        valid_ds,
        batch_size=EVAL_BS,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=collate_fn,
    )
    test_dl = DataLoader(
        test_ds,
        batch_size=EVAL_BS,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
        collate_fn=collate_fn,
    )

    projector = ItemProjector(in_dim=TEXT_EMB_DIM, out_dim=EMB_D, hidden_dim=256).to(device)
    optimizer = torch.optim.AdamW(projector.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

    best_score = -1.0

    for epoch in range(1, EPOCHS + 1):
        projector.train()
        pbar = tqdm(train_dl, desc=f"Epoch {epoch}/{EPOCHS}", leave=True)
        running = 0.0
        steps = 0

        for batch in pbar:
            hist_idx  = batch["hist_idx"].to(device)   # (B,L)
            hist_mask = batch["hist_mask"].to(device)  # (B,L)
            target_idx = batch["target_idx"].to(device)# (B,)

            B, L = hist_idx.shape

            # safe indices
            safe_idx = hist_idx.clone()
            safe_idx[~hist_mask] = 0

            # gather base text embeddings for history & target
            # (B,L,dim)
            hist_base = base_text_emb_t[safe_idx]
            # (B,dim)
            pos_base  = base_text_emb_t[target_idx]

            # project
            hist_proj = projector(hist_base)          # (B,L,D)
            pos_proj  = projector(pos_base)           # (B,D)

            # user embedding = mean over history (masked)
            m = hist_mask.float().unsqueeze(-1)       # (B,L,1)
            summed = (hist_proj * m).sum(dim=1)       # (B,D)
            count  = m.sum(dim=1).clamp(min=1.0)      # (B,1)
            user = summed / count
            user = F.normalize(user, dim=-1)          # (B,D)

            # InfoNCE logits with in-batch negatives
            logits = info_nce_logits(user, pos_proj, temp=TEMP)
            labels = torch.arange(logits.size(0), device=device)
            loss   = F.cross_entropy(logits, labels)

            optimizer.zero_grad(set_to_none=True)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(projector.parameters(), max_norm=1.0)
            optimizer.step()

            running += float(loss.item())
            steps   += 1
            pbar.set_postfix(loss=f"{running/steps:.4f}")


        val_metrics, E_item = eval_full_knn(
            projector,
            valid_dl,
            device,
            base_text_emb_t,
            Ks=(10, 20, 50),
            max_batches=VAL_MAX_BATCHES,
        )
        print("[Valid]", " | ".join([f"{k}:{v:.6f}" for k, v in val_metrics.items()]))

        score = (val_metrics["recall@10"] + val_metrics["ndcg@10"]) / 2.0
        if score >= best_score:
            best_score = score
            torch.save(projector.state_dict(), ARTIFACTS / "item_projector.pt")
            np.save(ARTIFACTS / "E_item_proj_128.npy", E_item)
            print(f"Saved best model (score={score:.6f}).")


    best_path = ARTIFACTS / "item_projector.pt"
    if best_path.exists():
        projector.load_state_dict(torch.load(best_path, map_location=device))
    else:
        print("[WARN] best model checkpoint not found; using last-epoch weights.")

    test_metrics, E_item = eval_full_knn(
        projector,
        test_dl,
        device,
        base_text_emb_t,
        Ks=(10, 20, 50),
        max_batches=TEST_MAX_BATCHES,
    )
    print("[Test]", " | ".join([f"{k}:{v:.6f}" for k, v in test_metrics.items()]))
    np.save(ARTIFACTS / "E_item_proj_128.npy", E_item)
    print("Saved projected item embedding matrix to", ARTIFACTS / "E_item_proj_128.npy")

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torch.nn.functional as F

# MUST match training
TEXT_EMB_DIM = 384
EMB_D = 128

class ItemProjector(nn.Module):
    def __init__(self, in_dim=TEXT_EMB_DIM, out_dim=EMB_D, hidden_dim=256):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, out_dim),
        )

    def forward(self, x):
        z = self.mlp(x)
        z = F.normalize(z, dim=-1)
        return z

projector = ItemProjector()
projector.load_state_dict(torch.load(
    ART_DIR / "item_projector.pt", map_location="cpu"
))
projector.eval()

ART_DIR = Path("/content/drive/MyDrive/Data/preprocessed_data/Electronics/optionB_nlp_model")

projector = ItemProjector()
projector.load_state_dict(torch.load(
    ART_DIR / "item_projector.pt",
    map_location="cpu"
))
projector.eval()

print("Loaded projector model!")

DATA_DIR = Path("/content/drive/MyDrive/Data/preprocessed_data/Electronics")

base_emb = np.load(DATA_DIR / "item_text_emb_384.npy").astype("float32")
E_item_proj = np.load(ART_DIR / "E_item_proj_128.npy").astype("float32")

base_emb_t = torch.from_numpy(base_emb).float()

with open(DATA_DIR / "mappings.json", "r") as f:
    maps = json.load(f)

item2idx = maps["item2idx"]
idx2item = {v: k for k, v in item2idx.items()}

items_df = pd.read_parquet(DATA_DIR / "items.parquet")

from sklearn.metrics.pairwise import cosine_similarity

def compute_user_embedding(history_idxs):
    h_base = base_emb_t[history_idxs]     # (L, 384)
    h_proj = projector(h_base)            # (L, 128)
    u = h_proj.mean(dim=0)                # (128,)
    u = F.normalize(u, dim=0)
    return u

def recommend_top_k(history_idxs, top_k=10):
    # get user emb as a numpy array
    user_emb = compute_user_embedding(history_idxs).detach().cpu().numpy().reshape(1, -1)

    # E_item_proj is already numpy
    sims = cosine_similarity(user_emb, E_item_proj)[0]

    top_ids = sims.argsort()[::-1][:top_k]
    return [idx2item[i] for i in top_ids], sims[top_ids]

valid_rows = []
with open(DATA_DIR / "valid.jsonl") as f:
    for line in f:
        valid_rows.append(json.loads(line))

sample = valid_rows[100]
history = sample["history"]

print("History item indices:", history)

rec_asins, rec_scores = recommend_top_k(history, top_k=10)

print("\nRecommendations:")
for asin, score in zip(rec_asins, rec_scores):
    title = items_df.loc[items_df['parent_asin'] == asin, 'item_text'].values[0]
    print(f"{asin} | {score:.4f} | {title[:120]}...")
